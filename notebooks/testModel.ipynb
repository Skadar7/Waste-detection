{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE CROP\n",
    "\n",
    "# PATH = './train/tree/'\n",
    "\n",
    "# onlyfiles = [f for f in listdir(PATH) if isfile(join(PATH, f))]\n",
    "\n",
    "# for path in onlyfiles:\n",
    "#     cap = cv2.VideoCapture(f'{PATH}/{path}')\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     frame_number = 127 * fps \n",
    "#     cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number-1)\n",
    "#     res, frame = cap.read()\n",
    "#     img_path = f\"images/Tree//{path[:-4]}_tree.jpg\"\n",
    "#     try:\n",
    "#         cv2.imwrite(img_path, frame)\n",
    "#     except:continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDWnet:\n",
    "    def __init__(self, hard_model, light_model = None):\n",
    "        self.light_model_path = light_model\n",
    "        self.hard_model_path = hard_model\n",
    "        self.cuda_flag = False\n",
    "        self.detect_model_classes = None\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda_flag = True \n",
    "        self.prepare_model()\n",
    "\n",
    "    def prepare_model(self):\n",
    "        if self.light_model_path is not None:\n",
    "            self.light_model = YOLO(self.light_model_path)\n",
    "            self.detect_model_classes = self.light_model.names\n",
    "            self.light_model.to('cuda') \n",
    "\n",
    "        if self.hard_model_path is not None:\n",
    "            self.hard_model = YOLO(self.hard_model_path)\n",
    "            self.detect_model_classes = self.hard_model.names\n",
    "            self.hard_model.to('cuda') \n",
    "\n",
    "    def get_class(self, result):\n",
    "        for res in result:\n",
    "            boxes = res.boxes.cpu().numpy()\n",
    "            classes = []\n",
    "\n",
    "            for box in boxes:\n",
    "                class_name = detect_model_classes[int(box.cls)]\n",
    "                classes.append(class_name)\n",
    "        return classes\n",
    "    \n",
    "    def post_process(self, detetction_result):\n",
    "        vals = list(detetction_result.values())\n",
    "        final_class = max(vals,key=vals.count)[0]\n",
    "        return final_class\n",
    "\n",
    "    def process_hard(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_number = 120 * fps # 2:05 - 2:15\n",
    "        last_frame_number = 135 * fps\n",
    "        conf = 0.5\n",
    "        frame_skip = 11\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number-1)\n",
    "        detection_results = dict()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            frame_id = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if frame_id == last_frame_number:\n",
    "                break\n",
    "            result = self.hard_model(frame, verbose=False, conf = conf)\n",
    "            detection_results[frame_id] = self.get_class(result)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id+frame_skip)\n",
    "        cap.release()\n",
    "        return detection_results\n",
    "        \n",
    "    # def process_light(self):\n",
    "        # cap = cv2.VideoCapture(data_path)\n",
    "        # frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "        # while cap.isOpened():\n",
    "        #     frames = []\n",
    "        #     frame_ids = []\n",
    "        #     timestamps = []\n",
    "        #     for i in range(self.batch_size):\n",
    "        #         success, frame = cap.read()\n",
    "        #         if not success:\n",
    "        #             break\n",
    "        #         timestamps.append(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "        #         frame_ids.append(int(cap.get(cv2.CAP_PROP_POS_FRAMES)))\n",
    "        #         frames.append(frame)\n",
    "        #     if len(frames) != 0:\n",
    "        #         frames = self.process_batch(frames, timestamps, frame_ids, save)\n",
    "        #         if save:\n",
    "        #             for frame in frames:\n",
    "        #                 out.write(frame)\n",
    "        #     if not success:\n",
    "        #         break\n",
    "\n",
    "    def predict(self, video_path, mode = 'hard_mode'):\n",
    "        if mode == 'hard_mode':\n",
    "            result = self.process_hard(video_path)\n",
    "            return self.post_process(result)\n",
    "        # elif self.mode == 'light_mode':\n",
    "        #     self.process_light(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARD_MODEL = './models/yolov8l_e20_b8_im720.pt'\n",
    "VIDEO_PATH = './train/brick/3554032.mp4'\n",
    "\n",
    "model = CDWnet(hard_model=HARD_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete\n"
     ]
    }
   ],
   "source": [
    "res_class = model.predict(VIDEO_PATH)\n",
    "print(res_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
