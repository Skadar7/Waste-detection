{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ultralytics import YOLO, RTDETR \n",
    "import torch\n",
    "import base64\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(detetction_result):\n",
    "    vals = list(detetction_result.values())\n",
    "    final_class = max(vals,key=vals.count)\n",
    "    return final_class\n",
    "\n",
    "def crop_video(dir_path, save_path):\n",
    "    files = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "    for path in files:\n",
    "        cap = cv2.VideoCapture(f'{dir_path}/{path}')\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_number = 127 * fps \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number-1)\n",
    "        res, frame = cap.read()\n",
    "        img_path = f\"{save_path}/{path[:-4]}_tree.jpg\"\n",
    "        try:\n",
    "            cv2.imwrite(img_path, frame)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def plot_boxes(frame, xyxy, label):\n",
    "    x1 = int(xyxy[0])\n",
    "    y1 = int(xyxy[1])\n",
    "    x2 = int(xyxy[2])\n",
    "    y2 = int(xyxy[3])\n",
    "\n",
    "    (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "    frame = cv2.rectangle(frame, (x1, y1 - 20), (x1 + w, y1), (0, 0, 255), -1)\n",
    "    frame = cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    frame = cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    return frame\n",
    "\n",
    "def convert_to_base64(frame):\n",
    "    success, buffer = cv2.imencode('.jpg', frame)\n",
    "    base64_img = base64.b64encode(buffer)\n",
    "    return base64_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDWnet:\n",
    "    def __init__(self, hard_model = None, light_model = None):\n",
    "        self.light_model_path = light_model\n",
    "        self.hard_model_path = hard_model\n",
    "        self.light_model = None\n",
    "        self.hard_model = None\n",
    "\n",
    "        self.cuda_flag = False\n",
    "        self.detect_model_classes = None\n",
    "        self.detection_mode = None\n",
    "        self.model_conf = 0.5\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda_flag = True \n",
    "        self.prepare_model()\n",
    "\n",
    "    def prepare_model(self):\n",
    "        if self.light_model_path is not None:\n",
    "            self.light_model = YOLO(self.light_model_path)\n",
    "            self.detect_model_classes = self.light_model.names\n",
    "            if self.cuda_flag:\n",
    "                self.light_model.to('cuda') \n",
    "\n",
    "        if self.hard_model_path is not None:\n",
    "            self.hard_model = YOLO(self.hard_model_path)  # RTDETR !\n",
    "            self.detect_model_classes = self.hard_model.names\n",
    "            if self.cuda_flag:\n",
    "                self.hard_model.to('cuda') \n",
    "\n",
    "    def handle_result(self, result, frame):\n",
    "        for res in result:\n",
    "            boxes = res.boxes.cpu().numpy()\n",
    "            images_data = []\n",
    "\n",
    "            for box in boxes:\n",
    "                class_name = self.detect_model_classes[int(box.cls)]\n",
    "                xyxy = box.xyxy[0]\n",
    "                confidence = str(round(box.conf[0].item(), 2))\n",
    "                label = f'{class_name}: {confidence}'\n",
    "\n",
    "                images_data.append([class_name, confidence, xyxy, label, frame])\n",
    "\n",
    "        if images_data:\n",
    "            most_conf_class = max(images_data, key = lambda x: x[1])\n",
    "            return most_conf_class\n",
    "        return None\n",
    "\n",
    "    def post_process(self, detection_results):\n",
    "        if self.detection_mode == 'hard_mode':\n",
    "            vals = list(detection_results.values())\n",
    "            cls_list = [i[0] for i in vals]\n",
    "\n",
    "            final_class = max(cls_list, key=cls_list.count)\n",
    "            cnf_list = [i for i in vals if i[0] == final_class]\n",
    "\n",
    "            max_conf = max(cnf_list, key = lambda x: x[1])\n",
    "            frame_num = list(detection_results.keys())[vals.index(max_conf)]\n",
    "\n",
    "            frame = plot_boxes(max_conf[4], max_conf[2], max_conf[3])\n",
    "        else:\n",
    "            final_class = detection_results[0]\n",
    "            frame = plot_boxes(detection_results[4], detection_results[2], detection_results[3])\n",
    "\n",
    "        base64_img = convert_to_base64(frame)\n",
    "        return final_class, base64_img\n",
    "\n",
    "    def process_hard(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_number = 120 * fps # 2:00 - 2:15\n",
    "        last_frame_number = 135 * fps\n",
    "        frame_skip = 11\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number-1)\n",
    "        detection_results = dict()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            frame_id = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if frame_id == last_frame_number:\n",
    "                break\n",
    "            result = self.hard_model(frame, verbose=False, conf = self.model_conf)\n",
    "            handled_res = self.handle_result(result, frame)\n",
    "            if handled_res:\n",
    "                detection_results[frame_id] = handled_res\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id+frame_skip)\n",
    "\n",
    "        cap.release()\n",
    "        return detection_results\n",
    "\n",
    "    def process_light(self, image_path):\n",
    "        result = self.light_model(image_path, verbose=False, conf = self.model_conf)\n",
    "        frame = cv2.imread(image_path)\n",
    "        detection_results = self.handle_result(result, frame)\n",
    "        return detection_results\n",
    "\n",
    "    def process_light_stream(self, stream_path):\n",
    "        cap = cv2.VideoCapture(stream_path)\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            result = self.light_model(frame, verbose=False, conf = self.model_conf)\n",
    "            detection_results = self.handle_result(result, frame)\n",
    "            \n",
    "            if detection_results:\n",
    "                yield self.post_process(detection_results)\n",
    "            else:\n",
    "                yield None, convert_to_base64(frame)\n",
    "\n",
    "    def predict(self, path, mode = 'hard_mode'):\n",
    "        self.detection_mode = mode\n",
    "\n",
    "        if self.detection_mode == 'hard_mode' and self.hard_model:\n",
    "            result = self.process_hard(path)\n",
    "        elif self.detection_mode == 'light_mode' and self.light_model:\n",
    "            result = self.process_light(path)\n",
    "        if result:\n",
    "            return self.post_process(result)\n",
    "        else:\n",
    "            return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARD_MODEL_PATH = '../models/yolov8l_e20_b8_im720.pt'\n",
    "VIDEO_DIR_PATH = '../videos'\n",
    "SAVE_PATH = './result.csv'\n",
    "\n",
    "model = CDWnet(hard_model=HARD_MODEL_PATH)\n",
    "\n",
    "FILES = [f for f in listdir(VIDEO_DIR_PATH) if isfile(join(VIDEO_DIR_PATH, f))]\n",
    "\n",
    "classes = {\n",
    "    'Brick': 'кирпич',\n",
    "    'Concrete': 'бетон',\n",
    "    'priming': 'грунт',\n",
    "    'Tree': 'дерево'\n",
    "}\n",
    "\n",
    "res = []\n",
    "\n",
    "for path in FILES:\n",
    "    class_res, image = model.predict(f'{VIDEO_DIR_PATH}/{path}')\n",
    "    res.append([path, classes[class_res]])\n",
    "\n",
    "with open(SAVE_PATH, 'w') as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n', delimiter=';')\n",
    "    writer.writerows(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
